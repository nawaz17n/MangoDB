{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-1. What are the key differences between SQL and NoSQL databases?\n",
    "* SQL stands for Structured Query Language and NoSQL stands for Not Only SQL databases serve different purposes and have distinct characteristics.\n",
    "\n",
    "### 1. Data Model:\n",
    "#### SQL Databases: \n",
    "Use a structured schema with tables, rows, and columns. Data is organized in a relational model, where relationships between tables are defined using foreign keys.\n",
    "#### NoSQL Databases: \n",
    "Use various data models, including document, key-value, column-family, and graph. They are more flexible and can handle unstructured or semi-structured data.\n",
    "### 2. Schema:\n",
    "#### SQL Databases: \n",
    "Have a fixed schema that requires a predefined structure. Changes to the schema can be complex and may require migrations.\n",
    "#### NoSQL Databases: \n",
    "Typically have a dynamic schema, allowing for more flexibility in data storage. New fields can be added without affecting existing data.\n",
    "### 3. Query Language:\n",
    "#### SQL Databases: \n",
    "Use SQL as the standard query language for defining and manipulating data. SQL provides powerful querying capabilities, including joins and complex transactions.\n",
    "#### NoSQL Databases: \n",
    "Use various query languages or APIs specific to the database type. They may not support complex queries or joins in the same way SQL does.\n",
    "### 4. Transactions:\n",
    "#### SQL Databases: \n",
    "Support ACID (Atomicity, Consistency, Isolation, Durability) properties ensuring reliable transactions and data integrity.\n",
    "#### NoSQL Databases: \n",
    "Often prioritize availability and partition tolerance over strict consistency (following the CAP theorem). Some NoSQL databases offer eventual consistency rather than strict ACID compliance.\n",
    "### 5. Scalability:\n",
    "#### SQL Databases: \n",
    "Typically scale vertically (adding more power to a single server). Horizontal scaling (adding more servers) can be challenging due to the relational model.\n",
    "#### NoSQL Databases: \n",
    "Designed for horizontal scaling, allowing them to handle large volumes of data and high traffic by distributing data across multiple servers.\n",
    "### 6. Use Cases:\n",
    "#### SQL Databases: \n",
    "Best suited for applications requiring complex queries, transactions, and data integrity, such as financial systems, ERP, and CRM applications.\n",
    "#### NoSQL Databases: \n",
    "Ideal for applications with large volumes of unstructured data, real-time analytics, content management, and scenarios requiring high availability and scalability, such as social media, IoT, and big data applications.\n",
    "### 7. Examples:\n",
    "* SQL Databases: MySQL, PostgreSQL, Oracle, Microsoft SQL Server.\n",
    "* NoSQL Databases: MongoDB (document), Cassandra (column-family), Redis (key-value), Neo4j (graph)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question - 2.What makes MongoDB a good choice for modern applications?\n",
    "\n",
    "* MongoDB is a popular NoSQL database that offers several features and advantages that make it a good choice for modern applications.\n",
    "#### 1. Flexible Schema:\n",
    "MongoDB uses a document-oriented data model allowing for a flexible schema. This means that documents in a collection can have different structures making it easy to adapt to changing application requirements without the need for complex migrations.\n",
    "#### 2. Scalability:\n",
    "MongoDB is designed for horizontal scalability allowing it to handle large volumes of data and high traffic loads. It supports sharding, which distributes data across multiple servers, enabling applications to scale out easily as demand grows.\n",
    "#### 3. High Performance:\n",
    "MongoDB provides high performance for read and write operations. Its in-memory processing capabilities and efficient indexing mechanisms contribute to fast query execution, making it suitable for real-time applications.\n",
    "#### 4. Rich Query Language:\n",
    "MongoDB offers a powerful and expressive query language that supports a wide range of queries, including filtering, sorting, and aggregation. This allows developers to perform complex data operations without needing to write extensive code.\n",
    "#### 5. Document Storage:\n",
    "Data is stored in BSON (Binary JSON) format, which allows for rich data types, including arrays and nested documents. This makes it easy to represent complex data structures and relationships within a single document.\n",
    "#### 6. Built-in Replication and High Availability:\n",
    "MongoDB supports replica sets, which provide automatic failover and data redundancy. This ensures high availability and data durability, making it suitable for mission-critical applications.\n",
    "#### 7. Geospatial Queries:\n",
    "MongoDB has built-in support for geospatial data and queries, making it a great choice for applications that require location-based services, such as mapping and location tracking.\n",
    "#### 8. Aggregation Framework:\n",
    "The aggregation framework in MongoDB allows for powerful data processing and transformation capabilities. It enables developers to perform complex data analysis and reporting directly within the database.\n",
    "#### 9. Integration with Modern Technologies:\n",
    "MongoDB integrates well with modern development frameworks and tools, including cloud services, microservices architectures, and containerization technologies like Docker and Kubernetes.\n",
    "#### 10. Community and Ecosystem:\n",
    "MongoDB has a large and active community, along with a rich ecosystem of tools, libraries, and resources. This support makes it easier for developers to find solutions, share knowledge, and access third-party integrations.\n",
    "#### 11. Cloud Services:\n",
    "MongoDB Atlas, the fully managed cloud database service, simplifies deployment, scaling, and management of MongoDB databases. It provides features like automated backups, monitoring, and security, making it easier for teams to focus on application development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-3. Explain the concept of collections in MongoDB.\n",
    "\n",
    "* In MongoDB a collection is a fundamental data structure that serves as a container for documents.#### \n",
    "\n",
    "#### 1. Definition:\n",
    "A collection is analogous to a table in a relational database. It is a grouping of MongoDB documents that share a similar structure or purpose. Each document within a collection can have a different schema, allowing for flexibility in data representation.\n",
    "#### 2. Documents:\n",
    "Documents are the individual records stored within a collection. They are represented in BSON (Binary JSON) format, which allows for rich data types, including arrays, nested objects, and various data types (strings, numbers, dates). Each document has a unique identifier called the _id field, which is automatically generated by MongoDB unless specified otherwise.\n",
    "#### 3. Schema Flexibility:\n",
    "Unlike traditional relational databases, collections in MongoDB do not require a predefined schema. This means that documents within the same collection can have different fields and data types. This flexibility is particularly useful for applications that evolve over time or deal with unstructured data.\n",
    "#### 4. Creating Collections:\n",
    "Collections are created automatically when a document is inserted into a non-existent collection. However, developers can also explicitly create collections using the createCollection command if they want to specify options such as validation rules, storage engine, or indexing.\n",
    "#### 5. Indexes:\n",
    "Collections can have indexes to improve query performance. MongoDB supports various types of indexes, including single-field, compound, geospatial, and text indexes. Indexes can be created on one or more fields within a collection to optimize read operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-4. How does MongoDB ensure high availability using replication?\n",
    "\n",
    "MongoDB ensures high availability through replica sets, which are groups of MongoDB servers that maintain the same dataset. Here are the key components of this mechanism:\n",
    "\n",
    "#### 1.Primary and Secondary Nodes: \n",
    "In a replica set one node acts as the primary handling all write operations while one or more secondary nodes replicate the data from the primary.\n",
    "\n",
    "#### 2.Automatic Failover: \n",
    "If the primary node fails the secondary nodes automatically detect the failure through heartbeat signals. An election process is initiated to select a new primary from the secondaries, ensuring continuous availability.\n",
    "\n",
    "#### 3.Oplog: \n",
    "The primary maintains an operation log (oplog) that records all changes. Secondary nodes replicate these changes from the oplog, keeping their data synchronized with the primary.\n",
    "\n",
    "#### 4.Read Preferences: \n",
    "Clients can configure read preferences to read from either the primary or secondary nodes, allowing for load balancing and improved read performance.\n",
    "\n",
    "#### 5.Arbiters: \n",
    "In cases where an odd number of nodes is needed for elections, arbiter nodes can be added. They participate in elections but do not store data, helping maintain a quorum.\n",
    "\n",
    "This replication strategy provides redundancy and fault tolerance, ensuring that MongoDB remains available even in the event of node failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questio-5. What are the main benefits of MongoDB Atlas?\n",
    "\n",
    "\n",
    "### Main Benefits of MongoDB Atlas\n",
    "\n",
    "#### Fully Managed Service: \n",
    "Handles database deployment, updates, backups, and scaling automatically.\n",
    "#### Global Distribution: \n",
    "Easily distribute data across multiple regions for low-latency access and disaster recovery.\n",
    "#### Scalability: \n",
    "Supports vertical and horizontal scaling with minimal effort.\n",
    "#### High Security: \n",
    "Provides built-in encryption, role-based access control, and compliance with standards like GDPR and HIPAA.\n",
    "#### Performance Monitoring: \n",
    "Offers real-time monitoring and performance optimization tools.\n",
    "* MongoDB Atlas simplifies database management while ensuring reliability, scalability, and security."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-6. What is the role of indexes in MongoDB, and how do they improve performance?\n",
    "\n",
    "\n",
    "### Role of Indexes in MongoDB and Their Impact on Performance\n",
    "Indexes in MongoDB play a crucial role in optimizing query performance and improving data retrieval efficiency. Here are the key points regarding their role and benefits:\n",
    "\n",
    "#### Faster Query Execution:\n",
    "Indexes allow MongoDB to quickly locate and access the documents that match a query, significantly reducing the amount of data that needs to be scanned. This leads to faster query execution times.\n",
    "\n",
    "#### Efficient Sorting:\n",
    "Indexes can be used to sort query results without requiring additional processing. When a query includes sorting on indexed fields, MongoDB can return results in the desired order directly from the index.\n",
    "\n",
    "#### Reduced Resource Consumption:\n",
    "By minimizing the number of documents scanned during a query, indexes reduce CPU and memory usage, leading to more efficient resource utilization and improved overall performance.\n",
    "\n",
    "#### Support for Complex Queries:\n",
    "Indexes enable the execution of complex queries, including those with multiple fields, range queries, and text searches. This enhances the flexibility and capability of the database to handle diverse query patterns.\n",
    "\n",
    "#### Types of Indexes:\n",
    "MongoDB supports various types of indexes, including single-field, compound, geospatial, and text indexes. Each type is designed to optimize specific query patterns, allowing developers to tailor indexing strategies to their application needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question- 7. Describe the stages of the MongoDB aggregation pipeline.\n",
    "\n",
    "* The MongoDB aggregation pipeline is a powerful framework for processing and transforming data in a collection. It consists of a series of stages, each performing a specific operation on the data.\n",
    "\n",
    "* $match : Filters documents based on a condition (like SQL WHERE clause).\n",
    "* $group: Groups documents by a field and performs aggregations (e.g., sum, average).\n",
    "* $project: Reshapes documents by including, excluding, or computing fields.\n",
    "* $sort: Sorts documents in ascending or descending order.\n",
    "* $limit: Limits the number of documents in the output.\n",
    "* $skip: Skips a specified number of documents.\n",
    "* $unwind: Deconstructs an array field into individual documents.\n",
    "* $lookup:This stage performs a left outer join with another collection, allowing you to combine documents from different collections based on a specified field.\n",
    "* $facet:This stage allows you to perform multiple independent aggregations within a single pipeline.\n",
    "* $merge:This stage allows you to write the results of the aggregation pipeline to a specified collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-8. What is sharding in MongoDB? How does it differ from replication?\n",
    "\n",
    "Sharding in MongoDB is a method for distributing data across multiple servers or clusters to ensure horizontal scalability. It allows MongoDB to handle large datasets and high-throughput applications by partitioning data into smaller, more manageable pieces called shards. Each shard is an independent database that contains a subset of the data, and together, they form a single logical database.\n",
    "\n",
    "### Key Features of Sharding:\n",
    "* Data Distribution: Sharding divides the dataset into chunks based on a shard key, which is a specific field in the documents.\n",
    "* Horizontal Scalability: As the data grows new shards can be added to the cluster without downtime allowing the system to scale out easily.\n",
    "* Load Balancing: MongoDB automatically balances the data across shards to ensure even distribution and optimal performance.\n",
    "* High Availability: Each shard can be configured as a replica set providing redundancy and failover capabilities.\n",
    "### How Does Sharding Differ from Replication?\n",
    "While both sharding and replication are techniques used in MongoDB to enhance performance and availability, they serve different \n",
    "\n",
    "### Purposes\n",
    "* Sharding:Primarily used for horizontal scaling and managing large datasets by distributing data across multiple servers.\n",
    "* Replication: Used for data redundancy and high availability by creating copies of the same data on multiple servers.\n",
    "### Data Structure:\n",
    "* Sharding: Involves partitioning data into distinct shards, each containing a subset of the overall dataset.\n",
    "* Replication: Involves maintaining identical copies of the same dataset across multiple nodes (replica sets).\n",
    "### Data Access: \n",
    "* Sharding:Queries may be directed to specific shards based on the shard key, allowing for efficient data retrieval from large datasets.\n",
    "* Replication: All read and write operations are typically directed to the primary node, with secondary nodes serving as backups.\n",
    "### Scalability vs. Availability:\n",
    "* Sharding: Focuses on scaling out the database to handle increased load and larger datasets.\n",
    "* Replication: Focuses on ensuring data availability and durability in case of node failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-9. What is PyMongo, and why is it used?\n",
    "\n",
    "PyMongo is the official Python driver for MongoDB, providing a way for Python applications to interact with MongoDB databases. It allows developers to perform various database operations, such as creating, reading, updating, and deleting documents, as well as managing collections and databases.\n",
    "\n",
    "### Key Features of PyMongo:\n",
    "#### Database Operations:\n",
    "* PyMongo provides methods to perform CRUD (Create, Read, Update, Delete) operations on MongoDB documents, making it easy to manipulate data.\n",
    "#### Connection Management:\n",
    "* It handles connections to MongoDB servers, including support for replica sets and sharded clusters, ensuring efficient communication with the database.\n",
    "#### Aggregation Framework:\n",
    "* PyMongo supports MongoDB's aggregation framework, allowing developers to perform complex data processing and analysis directly from their Python applications.\n",
    "#### Indexing:\n",
    "* It provides functionality to create and manage indexes, which can improve query performance.\n",
    "#### Support for BSON:\n",
    "* PyMongo can handle BSON (Binary JSON) data types, which are used by MongoDB, allowing for rich data structures, including arrays and nested documents.\n",
    "\n",
    "### Why is PyMongo Used?\n",
    "#### Ease of Use:\n",
    "* PyMongo offers a simple and intuitive API for interacting with MongoDB, making it accessible for developers familiar with Python.\n",
    "#### Integration with Python Applications:\n",
    "* It seamlessly integrates with Python applications, allowing developers to leverage MongoDB's capabilities within their existing codebases.\n",
    "#### Community and Documentation:\n",
    "* As the official MongoDB driver for Python, PyMongo has extensive documentation and a supportive community, making it easier for developers to find resources and troubleshoot issues.\n",
    "#### Performance:\n",
    "* PyMongo is optimized for performance, allowing efficient data access and manipulation, which is crucial for applications that require fast response times.\n",
    "#### Flexibility:\n",
    "* It supports various MongoDB features, including transactions, change streams, and gridFS, providing developers with the flexibility to build a wide range of applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-10. What are the ACID properties in the context of MongoDB transactions?\n",
    "\n",
    "* ACID properties refer to a set of principles that ensure reliable processing of database transactions. ACID stands for Atomicity, Consistency, Isolation, and Durability.\n",
    "\n",
    "### Atomicity :\n",
    "* Transactions are treated as a single unit either all operations succeed, or none do. If any operation fails, the entire transaction is rolled back, maintaining the database's previous state.\n",
    "\n",
    "### Consistency :\n",
    "* Transactions must transition the database from one valid state to another and After a transaction, the data must comply with the schema and validation rules.\n",
    "\n",
    "### Isolation : \n",
    "* Transactions operate independently, meaning the operations in one transaction are not visible to others until committed. This prevents interference and ensures that transactions do not affect each other.\n",
    "\n",
    "### Durability : \n",
    "* Transactions operate independently, meaning the operations in one transaction are not visible to others until committed. This prevents interference and ensures that transactions do not affect each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question- 11. What is the purpose of MongoDB’s explain() function?\n",
    "\n",
    "* The explain() function in MongoDB provides detailed information about the execution plan for a query, including the stages involved, the order of execution, and the estimated cost of each stage. It helps developers understand the performance of their queries and optimize them for better performance.\n",
    "\n",
    "* Query Execution Plan: The explain() function returns the execution plan for a given query, detailing how MongoDB processes the query. \n",
    "\n",
    "* Performance Metrics:  It provides various performance metrics, such as the time taken to execute the query, the number of documents examined, and the number of documents returned.\n",
    "\n",
    "* Index Usage: The output of explain() indicates whether the query is using an index and if so which index is being utilized.\n",
    "\n",
    "* Different Modes: The explain() function can be run in different verbosity modes (e.g., \"queryPlanner\", \"executionStats\", and \"allPlansExecution\"), allowing users to choose the level of detail they need for their analysis.\n",
    "\n",
    "* Optimization Guidance: By analyzing the output of explain(), developers can make informed decisions about query optimization, such as modifying queries, adding indexes, or restructuring data models to enhance performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question- 12.How does MongoDB handle schema validation?\n",
    "\n",
    "* MongoDB uses a schemaless data model, which means it does not require a predefined structure or schema for documents. This flexibility allows developers to define the structure of their documents based on their specific requirements and use cases.\n",
    "\n",
    "* MongoDB provides a rich set of validation mechanisms, including validation rules, default values, and validation operators, to ensure that documents meet specific criteria.\n",
    "\n",
    "### Validation Rules: \n",
    "MongoDB allows you to define validation rules using JSON Schema, a powerful and flexible schema definition language. You can specify required fields, data types, value ranges, and other constraints that documents must meet to be considered valid.\n",
    "\n",
    "### Validation Levels:\n",
    "\n",
    "#### Strict: \n",
    "* Documents that do not meet the validation criteria will be rejected during insertion or update operations.\n",
    "#### Moderate: \n",
    "* Documents that do not meet the criteria will generate a warning but will still be allowed to be inserted or updated.\n",
    "\n",
    "### Validation Actions: \n",
    "* When a document fails validation, you can configure the action that MongoDB should take:\n",
    "* Error: The operation will fail, and an error message will be returned.\n",
    "* Warn: The operation will succeed, but a warning will be logged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question- 13. What is the difference between a primary and a secondary node in a replica set?\n",
    "\n",
    "In MongoDB a replica set is a group of MongoDB servers that maintain the same dataset, providing redundancy and high availability. Within a replica set, there are two main types of nodes: primary nodes and secondary nodes.\n",
    "\n",
    "### Primary Node:- \n",
    "* Role: The primary node is the main node in a replica set that receives all write operations.\n",
    "* Data Consistency: The primary node holds the most up-to-date version of the data.\n",
    "* Election: In the event of a primary node failure, the replica set will automatically elect a new primary from the secondary nodes.\n",
    "* Read Operations: By default read operations are directed to the primary node.* \n",
    "* Replication: The primary node replicates its data to the secondary nodes, ensuring that they have the same dataset.\n",
    "\n",
    "### Secondary Node\n",
    "* Role: Secondary nodes are replicas of the primary node. They do not accept write operations directly but replicate the data from the primary node.\n",
    "* Data Consistency: Secondary nodes maintain copies of the data from the primary node, but they may not always be up-to-date due to replication lag.\n",
    "* Read Operations: Secondary nodes can be configured to handle read operations, depending on the read preference settings. \n",
    "* Failover: If the primary node fails, one of the secondary nodes can be elected as the new primary, ensuring high availability and fault tolerance.\n",
    "* Backup and Reporting: Secondary nodes can be used for backup purposes or for running read-heavy operations without impacting the performance of the primary node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question - 14. What security mechanisms does MongoDB provide for data protection?\n",
    "\n",
    "MongoDB incorporates a variety of security mechanisms to protect data and ensure secure access to the database.\n",
    "\n",
    "### Authentication: \n",
    "MongoDB supports multiple authentication methods to verify user identities, including:\n",
    "\n",
    "* SCRAM: The default mechanism that uses salted passwords for secure authentication.\n",
    "* LDAP: Integrates with existing directory services for user authentication.\n",
    "* Kerberos: Provides secure authentication for users and services in a network.\n",
    "* x.509 Certificates: Used for client and server authentication in secure environments.\n",
    "\n",
    "### Authorization: \n",
    "* MongoDB employs role-based access control (RBAC), allowing administrators to define roles with specific permissions. Users are assigned roles that grant access to certain resources and operations, ensuring that only authorized individuals can perform specific actions on the database.\n",
    "\n",
    "### Encryption:\n",
    "* Encryption at Rest: Data stored on disk can be encrypted using the Encrypted Storage Engine, protecting it from unauthorized access.\n",
    "* Encryption in Transit: Data transmitted over the network can be encrypted using TLS/SSL, safeguarding it from interception during communication between clients and servers.\n",
    "\n",
    "### Auditing: \n",
    "* MongoDB provides auditing capabilities that log database operations, including user access and administrative actions.\n",
    "\n",
    "### Network Security: \n",
    "* MongoDB can be configured to bind to specific IP addresses, limiting access to trusted sources. It also supports firewalls and Virtual Private Networks (VPNs) to enhance network security."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question- 15. Explain the concept of embedded documents and when they should be used.\n",
    "\n",
    "Embedded documents are documents that are stored as part of another document, rather than being stored as separate documents in a separate collection. Embedded documents can be used to represent hierarchical data structures, enabling more efficient querying and manipulation of the data.\n",
    "\n",
    "### When to Use Embedded Documents:\n",
    "* One-to-Few Relationships: Embedded documents are ideal for one-to-few relationships, where a parent document contains a limited number of related sub-documents.\n",
    "* Data Locality: When you frequently access a parent document and its embedded documents together, embedding can enhance performance.\n",
    "* Atomicity: MongoDB ensures that updates to a single document, including its embedded documents, are atomic.\n",
    "* Simplified Data Model: Embedding can lead to a more straightforward data model by reducing the need for complex joins or multiple collections.\n",
    "* Avoiding Joins: Since MongoDB does not support traditional joins like relational databases, embedding can help avoid the need for complex queries that would require joining multiple collections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question - 16. What is the purpose of MongoDB’s $lookup stage in aggregation?\n",
    "\n",
    "The $lookup stage in MongoDB's aggregation framework is used to perform a left outer join between two collections. It combines documents from the input array with documents from the specified collection, based on a specified condition.\n",
    "\n",
    "### Purpose:\n",
    "* Combines data from a primary collection and a secondary collection.\n",
    "* Matches documents based on specified fields.\n",
    "* Embeds the matching documents into an array field in the result.\n",
    "* Useful for querying related data across collections without denormalizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question - 17. What are some common use cases for MongoDB?\n",
    "\n",
    "* MongoDB is widely used for various applications due to its flexibility and scalability. Common use cases include:\n",
    "\n",
    "* ### *Content Management Systems (CMS):* \n",
    "Handles unstructured or semi-structured data like blog posts, articles, and media files, allowing for easy content updates and retrieval.\n",
    "\n",
    "* ### *E-commerce Platforms:*\n",
    "Manages product catalogs, customer details, and transaction data efficiently, enabling dynamic product variations and personalized user experiences.\n",
    "\n",
    "* ### *Real-Time Analytics:* \n",
    "Processes and analyzes data streams, such as user activity logs or IoT sensor data, providing immediate insights for decision-making.\n",
    "\n",
    "* ### *Mobile and Web Applications:* \n",
    "Supports dynamic schema changes for user-generated content and rapid iteration, making it suitable for applications with evolving data requirements.\n",
    "\n",
    "* ### *Gaming Applications:*\n",
    "Stores player profiles, in-game assets, and real-time leaderboards, facilitating high write loads and real-time data processing.\n",
    "\n",
    "* ### *Big Data Applications:* \n",
    "Handles large volumes of unstructured or semi-structured data for data lakes, enabling efficient storage and analysis of diverse data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question - 18. What are the advantages of using MongoDB for horizontal scaling?\n",
    "\n",
    "* MongoDB offers several advantages for horizontal scaling, making it a popular choice for applications that require high availability and the ability to handle large volumes of data.\n",
    "\n",
    "* #### *Distributes Data:* \n",
    "Automatically divides data across multiple servers (shards) based on a shard key, ensuring balanced data distribution and preventing any single server from becoming a bottleneck.\n",
    "\n",
    "* #### *Increases Performance:* \n",
    "Queries and writes are distributed across shards, reducing the load on individual servers and significantly improving overall speed and responsiveness.\n",
    "\n",
    "* #### *Supports High Availability:* \n",
    "Each shard can have its own replica set, ensuring fault tolerance and minimal downtime in case of server failures, which is crucial for mission-critical applications.\n",
    "\n",
    "* #### *Handles Large Datasets:* \n",
    "Easily scales storage capacity by adding more shards as data grows, allowing organizations to manage large volumes of data without performance degradation.\n",
    "\n",
    "* #### *Cost-Effective:* \n",
    "Enables scaling with commodity hardware rather than relying on expensive high-end servers, making it a more economical solution for growing data needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question - 19. How do MongoDB transactions differ from SQL transactions?\n",
    "\n",
    "* MongoDB transactions and SQL transactions serve the same fundamental purpose of ensuring data integrity and consistency during operations that involve multiple documents or tables. \n",
    "\n",
    "### Data Model:\n",
    "* *MongoDB:*   MongoDB is a document-oriented NoSQL database that stores data in BSON format. Transactions can span multiple documents within a single collection or across multiple collections, allowing for more flexible data structures.\n",
    "*SQL:*   SQL databases are based on a relational model, where data is organized into tables with predefined schemas. Transactions typically operate within a single table or across multiple related tables using foreign keys.\n",
    "\n",
    "### ACID Compliance:\n",
    "* *MongoDB:*   As of version 4.0, MongoDB supports multi-document ACID transactions, ensuring that all operations within a transaction are atomic, consistent, isolated, and durable. However, earlier versions only supported atomic operations at the document level.\n",
    "* *SQL:*   SQL databases have traditionally supported ACID transactions from the outset, ensuring strong consistency and integrity across multiple rows and tables.\n",
    "\n",
    "### Isolation Levels:\n",
    "* *MongoDB:*   MongoDB provides snapshot isolation for transactions, meaning that transactions see a consistent snapshot of the data at the start of the transaction. This can lead to less contention but may not provide the same level of isolation as some SQL databases.\n",
    "* *SQL:*   SQL databases offer various isolation levels (e.g., READ COMMITTED, REPEATABLE READ, SERIALIZABLE) that allow developers to choose the level of consistency and concurrency control needed for their applications.\n",
    "\n",
    "### Performance:\n",
    "* *MongoDB:*   Transactions in MongoDB can introduce overhead, especially when spanning multiple documents or collections. However, MongoDB is designed for high throughput and can handle many concurrent operations efficiently.\n",
    "* *SQL:*   SQL transactions can also introduce overhead, particularly with complex joins and locking mechanisms. However, they are optimized for relational data access patterns.\n",
    "\n",
    "### Syntax and Implementation:\n",
    "* *MongoDB:*   Transactions in MongoDB are initiated using the startSession() method, and operations are wrapped in a session context. The syntax is different from traditional SQL, as it uses JavaScript-like syntax for operations.\n",
    "* *SQL:*   SQL transactions are typically initiated with BEGIN TRANSACTION, followed by a series of SQL statements, and concluded with COMMIT or ROLLBACK. The syntax is standardized across SQL databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question - 20. What are the main differences between capped collections and regular collections?\n",
    "\n",
    "Capped collections in MongoDB are a special type of collection that have specific characteristics and behaviors that differentiate them from regular collections.\n",
    "\n",
    "\n",
    "#### *Fixed Size:*\n",
    "* *Capped Collections:* Capped collections have a fixed size limit defined in bytes. Once this limit is reached, the oldest documents are automatically removed to make space for new documents. This behavior ensures that the collection does not grow indefinitely.\n",
    "* *Regular Collections:* Regular collections do not have a size limit. They can grow as needed, depending on the amount of data being inserted, until the storage capacity of the database is reached.\n",
    "\n",
    "#### *Insertion Order:*\n",
    "* *Capped Collections:* Capped collections maintain the order of document insertion. The documents are stored in the order they are added, and this order is preserved when retrieving documents.\n",
    "* *Regular Collections:* Regular collections do not guarantee any specific order of documents unless an index is created to enforce a particular order. The order of documents can change based on various operations, such as updates or deletions.\n",
    "\n",
    "#### *Document Deletion:*\n",
    "* *Capped Collections:* Documents in capped collections are automatically deleted in a first-in, first-out (FIFO) manner when the size limit is reached. This means that the oldest documents are removed to accommodate new ones.\n",
    "* *Regular Collections:* In regular collections, documents are deleted only when explicitly removed by a delete operation. There is no automatic deletion based on size or age.\n",
    "\n",
    "#### *Indexing:*\n",
    "* *Capped Collections:* Capped collections automatically create an index on the _id field, which is unique for each document. However, they do not support secondary indexes, which limits the types of queries that can be performed.\n",
    "* *Regular Collections:* Regular collections support multiple indexes, including secondary indexes, allowing for more complex queries and efficient data retrieval.\n",
    "\n",
    "#### *Use Cases:*\n",
    "* *Capped Collections:* Capped collections are ideal for use cases where you need to store a fixed-size log of events, such as logging systems, real-time data feeds, or caching scenarios where only the most recent data is relevant.\n",
    "* *Regular Collections:* Regular collections are suitable for general-purpose data storage where the size and lifespan of the data are not predetermined, such as user profiles, product catalogs, and other dynamic datasets.\n",
    "\n",
    "#### *Performance:*\n",
    "* *Capped Collections:* Capped collections can offer better performance for certain use cases, as they are optimized for high-throughput insert operations and do not require complex management of document deletion.\n",
    "* *Regular Collections:* Regular collections may incur overhead due to the need for managing document growth, deletions, and indexing, which can affect performance in write-heavy scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question - 21. What is the purpose of the *'$match'* stage in MongoDB’s aggregation pipeline?\n",
    "\n",
    "The *'*'$match'*'* stage in MongoDB’s aggregation pipeline is used to filter documents from the input collection based on specified criteria. It serves a similar purpose to the *'find()'* method but is integrated into the aggregation framework, allowing for more complex data processing and transformation.\n",
    "\n",
    "### *Purpose of the *'$match'* Stage*\n",
    "\n",
    "* #### Filtering Documents:\n",
    "The primary purpose of the *'$match'* stage is to filter documents that meet certain conditions. Only the documents that satisfy the specified criteria will be passed to the next stage in the pipeline, reducing the amount of data processed in subsequent stages.\n",
    "\n",
    "* #### Using Query Operators:\n",
    "The *'$match'* stage supports a wide range of query operators, such as $eq, $gt, $lt, $in, and logical operators like $and, $or, and $not. This allows for complex filtering conditions to be applied to the documents.\n",
    "\n",
    "* #### Improving Performance:\n",
    "By filtering out unnecessary documents early in the aggregation pipeline, the *'$match'* stage can improve performance. It reduces the amount of data that needs to be processed in later stages, which can lead to faster query execution times.\n",
    "\n",
    "* #### Combining with Other Stages:\n",
    "The *'$match'* stage can be used in conjunction with other aggregation stages, such as $group, $sort, and $project. This allows for powerful data transformations and aggregations based on filtered data.\n",
    "\n",
    "* #### Placement in the Pipeline:\n",
    "The *'$match'* stage can be placed at the beginning or in the middle of the aggregation pipeline. Placing it early can help optimize performance by reducing the dataset size before further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question- 22. How can you secure access to a MongoDB database?\n",
    "\n",
    "#### Authentication:\n",
    "* Use SCRAM (Salted Challenge Response Authentication Mechanism) or LDAP to authenticate users.\n",
    "* Enable MongoDB authentication to ensure that only authorized users can access the database.\n",
    "\n",
    "#### Authorization (Role-Based Access Control):\n",
    "* Implement RBAC to define and enforce access control at the database level, assigning users to specific roles with defined permissions.\n",
    "* Use built-in roles or create custom roles for fine-grained access control.\n",
    "\n",
    "#### Encryption:\n",
    "* Encryption at Rest: Enable the encrypted storage engine to encrypt data stored on disk.\n",
    "* Encryption in Transit: Use TLS/SSL to encrypt data transmitted between MongoDB clients and servers to protect against interception.\n",
    "\n",
    "#### Auditing:\n",
    "* Enable auditing to track user actions and detect unauthorized access attempts or suspicious behavior.\n",
    "\n",
    "#### IP Whitelisting and Network Security:\n",
    "* Restrict database access to trusted IP addresses using IP whitelisting.\n",
    "* Use firewalls to prevent unauthorized external access.\n",
    "\n",
    "#### Disable Unused Features:\n",
    "* Disable unnecessary services like the MongoDB HTTP interface and unused ports to reduce the attack surface.\n",
    "\n",
    "#### Backup Security:\n",
    "* Ensure that backups are encrypted and stored securely to prevent unauthorized access to sensitive data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question - 23. What is MongoDB’s WiredTiger storage engine, and why is it important?\n",
    "\n",
    "MongoDB’s WiredTiger storage engine is the default storage engine for MongoDB starting from version 3.2. It is designed to provide high performance, scalability, and efficient data management. \n",
    "\n",
    "### Key Features of WiredTiger\n",
    "\n",
    "* #### *Document-Level Locking:*\n",
    "WiredTiger uses document-level locking, which allows multiple operations to occur concurrently on different documents. This improves performance and throughput, especially in write-heavy workloads, as it reduces contention compared to collection-level or database-level locking.\n",
    "\n",
    "* #### *Compression:*\n",
    "WiredTiger supports data compression, which helps reduce the amount of disk space used by the database. It offers various compression algorithms, such as Snappy and Zlib, allowing users to choose the level of compression that best fits their needs. This feature not only saves storage space but can also improve I/O performance.\n",
    "\n",
    "* #### *Memory-Mapped Files:*\n",
    "WiredTiger utilizes memory-mapped files to manage data storage, which allows the operating system to handle caching and memory management. This can lead to better performance by leveraging the operating system's capabilities for efficient memory usage.\n",
    "\n",
    "* #### *Multi-Version Concurrency Control (MVCC):*\n",
    "WiredTiger implements MVCC, which allows readers to access a consistent snapshot of the data without being blocked by writers. This enhances read performance and ensures that read operations do not interfere with write operations, providing a more responsive experience for applications.\n",
    "\n",
    "* #### *Checkpointing:*\n",
    "WiredTiger uses a checkpointing mechanism to ensure data durability and consistency. Checkpoints are created periodically, allowing the system to recover to a consistent state in the event of a failure.\n",
    "\n",
    "* #### *Scalability:*\n",
    "The architecture of WiredTiger is designed to scale efficiently with increasing data volumes and workloads. It can handle large datasets and high-throughput applications, making it suitable for modern applications that require robust performance.\n",
    "Importance of WiredTiger\n",
    "\n",
    "* #### *Performance Improvements:*\n",
    "The features of WiredTiger, such as document-level locking and MVCC, significantly enhance the performance of MongoDB, especially in environments with high concurrency and large datasets. This makes it suitable for applications that require fast read and write operations.\n",
    "\n",
    "* #### *Efficient Resource Utilization:*\n",
    "With its support for compression and memory-mapped files, WiredTiger optimizes resource usage, reducing the overall storage footprint and improving I/O performance. This is particularly important for organizations looking to minimize costs associated with storage and infrastructure.\n",
    "\n",
    "* #### *Enhanced Data Integrity:*\n",
    "The checkpointing and MVCC mechanisms in WiredTiger contribute to data integrity and durability, ensuring that data remains consistent even in the event of failures. This is critical for applications that require reliable data storage and retrieval.\n",
    "\n",
    "* #### *Flexibility for Developers:*\n",
    "WiredTiger provides developers with options for tuning performance through configuration settings, such as choosing different compression algorithms and adjusting cache sizes. This flexibility allows developers to optimize the database for their specific use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Question- 1. Write a Python script to load the Superstore dataset from a CSV file into MongoDB.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"superstore.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>11/8/2016</td>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>11/8/2016</td>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2016-138688</td>\n",
       "      <td>6/12/2016</td>\n",
       "      <td>6/16/2016</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90036</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>10/11/2015</td>\n",
       "      <td>10/18/2015</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>10/11/2015</td>\n",
       "      <td>10/18/2015</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
       "0       1  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
       "1       2  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
       "2       3  CA-2016-138688   6/12/2016   6/16/2016    Second Class    DV-13045   \n",
       "3       4  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
       "4       5  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
       "\n",
       "     Customer Name    Segment        Country             City  ...  \\\n",
       "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
       "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "\n",
       "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
       "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
       "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
       "\n",
       "                                        Product Name     Sales  Quantity  \\\n",
       "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
       "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
       "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
       "\n",
       "   Discount    Profit  \n",
       "0      0.00   41.9136  \n",
       "1      0.00  219.5820  \n",
       "2      0.00    6.8714  \n",
       "3      0.45 -383.0310  \n",
       "4      0.20    2.5164  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"superstore_db\"]\n",
    "collection = db[\"superstore_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully inserted 9994 records into MongoDB.\n"
     ]
    }
   ],
   "source": [
    "if data_dict:\n",
    "    collection.insert_many(data_dict)\n",
    "    print(f\"Successfully inserted {len(data_dict)} records into MongoDB.\")\n",
    "else:\n",
    "    print(\"No data to insert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Question - 2.Retrieve and print all documents from the Orders collection.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db[\"superstore_data\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = collection.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    print(doc)\n",
    "    \n",
    "'''I can't display the file output on GitHub due to size limitations'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Question-3. Count and display the total number of documents in the Orders collection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_documents = collection.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents in the Superstore collection is :- 39976\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of documents in the Superstore collection is :- {total_documents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Question-4. Write a query to fetch all orders from the \"West\" region.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_orders = collection.find({\"Region\": \"West\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for order in west_orders:\n",
    "    print(order)\n",
    "\n",
    "'''I can't display the file output on GitHub due to size limitations'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Question-5. Write a query to find orders where Sales is greater than 500.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_sales_orders = collection.find({\"Sales\": {\"$gt\": 500}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for order in high_sales_orders:\n",
    "    print(order)\n",
    "\n",
    "'''I can't display the file output on GitHub due to size limitations'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Question-6. Fetch the top 3 orders with the highest Profit.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_profitable_orders = collection.find().sort(\"Profit\", -1).limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6798adc75a7a33d83efe5814'), 'Row ID': 6827, 'Order ID': 'CA-2016-118689', 'Order Date': '10/2/2016', 'Ship Date': '10/9/2016', 'Ship Mode': 'Standard Class', 'Customer ID': 'TC-20980', 'Customer Name': 'Tamara Chand', 'Segment': 'Corporate', 'Country': 'United States', 'City': 'Lafayette', 'State': 'Indiana', 'Postal Code': 47905, 'Region': 'Central', 'Product ID': 'TEC-CO-10004722', 'Category': 'Technology', 'Sub-Category': 'Copiers', 'Product Name': 'Canon imageCLASS 2200 Advanced Copier', 'Sales': 17499.95, 'Quantity': 5, 'Discount': 0.0, 'Profit': 8399.976}\n",
      "{'_id': ObjectId('6798a6015a7a33d83efe3105'), 'Row ID': 6827, 'Order ID': 'CA-2016-118689', 'Order Date': '10/2/2016', 'Ship Date': '10/9/2016', 'Ship Mode': 'Standard Class', 'Customer ID': 'TC-20980', 'Customer Name': 'Tamara Chand', 'Segment': 'Corporate', 'Country': 'United States', 'City': 'Lafayette', 'State': 'Indiana', 'Postal Code': 47905, 'Region': 'Central', 'Product ID': 'TEC-CO-10004722', 'Category': 'Technology', 'Sub-Category': 'Copiers', 'Product Name': 'Canon imageCLASS 2200 Advanced Copier', 'Sales': 17499.95, 'Quantity': 5, 'Discount': 0.0, 'Profit': 8399.976}\n",
      "{'_id': ObjectId('6798a1f75a7a33d83efe09f7'), 'Row ID': 6827, 'Order ID': 'CA-2016-118689', 'Order Date': '10/2/2016', 'Ship Date': '10/9/2016', 'Ship Mode': 'Standard Class', 'Customer ID': 'TC-20980', 'Customer Name': 'Tamara Chand', 'Segment': 'Corporate', 'Country': 'United States', 'City': 'Lafayette', 'State': 'Indiana', 'Postal Code': 47905, 'Region': 'Central', 'Product ID': 'TEC-CO-10004722', 'Category': 'Technology', 'Sub-Category': 'Copiers', 'Product Name': 'Canon imageCLASS 2200 Advanced Copier', 'Sales': 17499.95, 'Quantity': 5, 'Discount': 0.0, 'Profit': 8399.976}\n"
     ]
    }
   ],
   "source": [
    "for order in top_profitable_orders:\n",
    "    print(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Question- 7. Update all orders with Ship Mode as \"First Class\" to \"Premium Class.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated 1538 orders.\n"
     ]
    }
   ],
   "source": [
    "updated_orders = collection.update_many({\"Ship Mode\": \"First Class\"}, {\"$set\": {\"Ship Mode\": \"Premium Class\"}})\n",
    "print(f\"Successfully updated {updated_orders.modified_count} orders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Question- 8. Delete all orders where Sales is less than 50.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully deleted 19396 orders.\n"
     ]
    }
   ],
   "source": [
    "deleted_orders = collection.delete_many({\"Sales\": {\"$lt\": 50}})\n",
    "print(f\"Successfully deleted {deleted_orders.deleted_count} orders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Question- 9. Use aggregation to group orders by Region and calculate total sales per reg.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_orders = [\n",
    "    {\"$group\": {\"_id\": \"$Region\", \"Total Sales\": {\"$sum\": \"$Sales\"}}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.aggregate(grouped_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'East', 'Total Sales': 2604550.82}\n",
      "{'_id': 'West', 'Total Sales': 2778746.478}\n",
      "{'_id': 'South', 'Total Sales': 1504093.248}\n",
      "{'_id': 'Central', 'Total Sales': 1918447.3832}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Question- 10. Fetch all distinct values for Ship Mode from the collection.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Premium Class', 'Same Day', 'Second Class', 'Standard Class']\n"
     ]
    }
   ],
   "source": [
    "distinct_ship_modes = collection.distinct(\"Ship Mode\")\n",
    "print(distinct_ship_modes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Question- 11. Count the number of orders for each category.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_count_by_category = [\n",
    "    {\"$group\": {\"_id\": \"$Category\", \"Order Count\": {\"$sum\": 1}}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.aggregate(order_count_by_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Office Supplies, Order Count: {'_id': 'Office Supplies', 'Order Count': 8304}\n",
      "Category: Technology, Order Count: {'_id': 'Technology', 'Order Count': 5984}\n",
      "Category: Furniture, Order Count: {'_id': 'Furniture', 'Order Count': 6292}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(f\"Category: {result['_id']}, Order Count: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
